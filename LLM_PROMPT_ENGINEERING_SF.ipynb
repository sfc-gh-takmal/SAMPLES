{
 "metadata": {
  "kernelspec": {
   "display_name": "Snowflake SQL",
   "language": "sql",
   "name": "sql"
  },
  "language_info": {
   "name": "sql"
  },
  "lastEditStatus": {
   "notebookId": "6l3aoaxob64ljzpbibnx",
   "authorId": "1935988576203",
   "authorName": "TAJA",
   "authorEmail": "taj.akmal@snowflake.com",
   "sessionId": "3b010671-c66a-42f9-a64f-14e035f5c8c0",
   "lastEditTime": 1753289042428
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0f5ebf0-79b9-4aba-bba7-20eec1cb1359",
   "metadata": {
    "name": "md_prompt_engineering",
    "collapsed": false
   },
   "source": "# Prompt Engineering with Snowflake Cortex\n\nThis notebook demonstrates how to leverage Snowflake's `AI_COMPLETE` function to interact with large language models (LLMs).  \nUsing well‑crafted prompts is critical for obtaining accurate and useful responses. The examples below illustrate best practices for prompt engineering—including clear instructions, structured output, chain‑of‑thought reasoning, few‑shot examples, role prompting, and tuning model parameters.\n\n> **Note:** The queries shown here are examples. You should modify the model names and parameters based on the models available in your Snowflake environment.  For deterministic outputs, lower the temperature; for more creative outputs, increase it. Always test prompts with different settings and review the outputs before using them in production.\n"
  },
  {
   "cell_type": "markdown",
   "id": "7c5d4aea-a1fc-4ac0-a43f-5c974940ec72",
   "metadata": {
    "name": "md_best_practices"
   },
   "source": [
    "## Best Practices for Prompt Engineering\n",
    "\n",
    "Effective prompts guide the model to produce reliable, structured responses. Consider these general guidelines when designing prompts:\n",
    "\n",
    "- **Be clear and specific:** Describe the task explicitly, including necessary context and the desired format.  If the task involves multiple steps, enumerate them.\n",
    "- **Repeat critical instructions:** Reinforce important constraints at the end of the prompt—LLMs often prioritise the most recent instructions.\n",
    "- **Use structural markers:** Separate sections of your prompt with separators (e.g. `---`) or tags such as `<instructions>`, `<thinking>`, and `<answer>` to clearly delineate content, reasoning, and final answers.\n",
    "- **Provide examples:** Show a few diverse examples of inputs and desired outputs so the model learns the pattern (few‑shot prompting).  Wrap examples in tags like `<example>` to help the model parse them.\n",
    "- **Encourage step‑by‑step thinking:** For complex reasoning, instruct the model to think through the problem step by step or include chain‑of‑thought tags.  This often improves correctness.\n",
    "- **Specify the output structure:** Ask for specific formats (e.g. JSON) and, when available, use the `response_format` argument to enforce a JSON schema.  Structured outputs reduce parsing logic in SQL and improve consistency.\n",
    "- **Tune model parameters:** Adjust `temperature` and `top_p` to control randomness.  A low `temperature` (e.g. 0–0.3) yields deterministic responses; higher values (0.7–1.0) encourage diversity.  Change one parameter at a time and evaluate the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a41082-a91a-4952-a1c9-22d1942bf118",
   "metadata": {
    "name": "md_simple_prompt"
   },
   "source": [
    "## 1. Simple Prompt\n",
    "\n",
    "A simple prompt asks a single, well‑defined question.  Use clear language and avoid ambiguity.  When you only need a short answer and do not require a specific format, default parameters often suffice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea86a1d-43f5-4c23-bd5e-bcc0dd2e96e7",
   "metadata": {
    "name": "ai_complete_simple",
    "language": "sql"
   },
   "outputs": [],
   "source": [
    "-- Ask a direct question using the default model\n",
    "SELECT AI_COMPLETE(\n",
    "  'llama3.2-3b',\n",
    "  'What are large language models and why are they important in modern AI?'  \n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050a8cd6-cfff-4914-b872-10fa32207b73",
   "metadata": {
    "name": "md_llm_judge"
   },
   "source": [
    "## 2. LLM as a Judge (Self‑Evaluation)\n",
    "\n",
    "You can chain calls to `AI_COMPLETE` to have one model answer a question and a second model evaluate that answer.  Use this pattern to rate responses, classify them, or check policy compliance.  The grading prompt should instruct the evaluator to return a structured result (e.g. a JSON object with a score).  Parsing the output with `PARSE_JSON` makes it easy to extract fields.\n",
    "\n",
    "Below, we ask a model to answer a simple question and then ask a different model to score the answer based on length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c270865c-e0ed-4d8b-8e63-58cc340c30fe",
   "metadata": {
    "name": "llm_as_a_judge",
    "language": "sql"
   },
   "outputs": [],
   "source": "-- Define the question\nSET question_text = 'How many words are in your answer?';\n\nWITH qa AS (\n  SELECT\n    $question_text AS question,\n    AI_COMPLETE(\n      model  => 'llama3.2-3b',\n      prompt => $question_text\n    ) AS answer\n),\ngraded AS (\n  SELECT\n    question,\n    answer,\n    AI_COMPLETE(\n      model => 'claude-3-7-sonnet',\n      prompt => 'Score the following answer on a scale of 1 to 10 for answering the question completely.\n\nQuestion: ' || question || '\nAnswer: ' || answer,\n      model_parameters => { 'temperature': 0 },\n      response_format => {\n        'type': 'json',\n        'schema': {\n          'type': 'object',\n          'properties': {\n            'score': { 'type': 'integer' }\n          }\n        }\n      }\n    ) AS evaluation_json\n  FROM qa\n)\nSELECT \n  question, \n  answer, \n  evaluation_json:score::INT AS score\nFROM graded;"
  },
  {
   "cell_type": "markdown",
   "id": "72754afe-dce6-4144-9e66-763478afb9b2",
   "metadata": {
    "name": "md_tags_cot"
   },
   "source": [
    "## 3. Using Tags and Chain‑of‑Thought Reasoning\n",
    "\n",
    "For tasks that require reasoning, you can instruct the model to expose its thinking process inside specific tags like `<thinking>` or `<analysis>`.  At the end of the prompt, repeat the desired output structure to reinforce it.  When evaluating the answer, focus on the content in the `<answer>` tags.\n",
    "\n",
    "The example below asks the model to calculate which company retreat option fits a budget.  We instruct it to show intermediate calculations inside `<thinking>` tags and provide a final recommendation outside the tags.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428d0654-6a1e-4aa6-ad1f-24a112086f8e",
   "metadata": {
    "name": "tags_cot",
    "language": "sql"
   },
   "outputs": [],
   "source": "-- Chain of thought with custom tags\nSELECT AI_COMPLETE(\n  'claude-4-sonnet',\n  $$A tech startup has grown from 45 employees to 180 employees this year! They want to celebrate with a company retreat. They have a budget of $125,000 and are considering two options:\n\n' ||\n  'Option A: 3‑day retreat at a mountain resort ($650 per person for 3 days, includes meals)\n' ||\n  'Option B: 2‑day retreat at a beach resort ($420 per person for 2 days) + $200 per person bonus\n\n' ||\n  'Which option fits within their budget?\n\n' ||\n  'Think through the calculations inside <thinking> tags, then provide your final recommendation in <answer> tags.\n\n' ||\n  'Format:\n<thinking>...step‑by‑step calculations...</thinking>\n<answer>...your recommendation...</answer>$$\n);\n"
  },
  {
   "cell_type": "markdown",
   "id": "c5b3b3d6-fa9b-4b55-8351-172a1ecea9dd",
   "metadata": {
    "name": "md_structured_output"
   },
   "source": [
    "## 4. Structured Output with JSON Schema\n",
    "\n",
    "When you need to extract information reliably from model outputs, ask the model to respond in JSON and use the `response_format` argument.  Define a JSON schema with the expected properties and data types.  Setting a low `temperature` improves determinism.  Snowflake will validate the response against the schema, ensuring that the model outputs valid JSON.\n",
    "\n",
    "In this example, we summarise a product review and classify its sentiment.  The `response_format` enforces a JSON object with two properties—`summary` (a string) and `sentiment` (one of `positive`, `negative`, or `neutral`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e177736-cc81-4fe2-8eb0-ecfa5e7a2fbd",
   "metadata": {
    "name": "json_output",
    "language": "sql"
   },
   "outputs": [],
   "source": "SELECT AI_COMPLETE(\n  model => 'claude-4-sonnet',\n  prompt => 'Summarise the following product review in one sentence and classify its overall sentiment as positive, negative, or neutral:\n\"I''m very happy with the battery life but the screen is too dim.\"',\n  response_format => {\n    'type': 'json',\n    'schema': {\n      'type': 'object',\n      'properties': {\n        'summary': {'type': 'string'},\n        'sentiment': {'type': 'string', 'enum': ['positive','negative','neutral']}\n      },\n      'required': ['summary','sentiment']\n    }\n  },\n  model_parameters => { 'temperature': 0 }\n);"
  },
  {
   "cell_type": "markdown",
   "id": "057f702a-732c-425c-b8df-e09b300f2e08",
   "metadata": {
    "name": "md_model_parameters"
   },
   "source": [
    "## 5. Tuning Model Parameters\n",
    "\n",
    "`temperature` and `top_p` control the randomness of the output.  Lower values (e.g. `temperature = 0.0`) yield more deterministic answers; higher values (e.g. `temperature = 0.8`) encourage diverse phrasing.  Tune one parameter at a time.  You can also set `max_tokens` to limit the length of the output.\n",
    "\n",
    "Below we generate customer service responses to the same message using two different temperatures.  Notice how the tone changes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b861f768-50ab-43c7-a70c-1f723297800f",
   "metadata": {
    "name": "model_parameters",
    "language": "sql"
   },
   "outputs": [],
   "source": "-- Example messages\nWITH support_tickets AS (\n  SELECT * FROM VALUES\n    ('High priority billing issue needs resolution'),\n    ('Customer confused about new feature'),\n    ('Product recommendation request for enterprise client')\n  AS t(customer_message)\n)\nSELECT \n  customer_message,\n  -- Creative response with higher temperature\n  AI_COMPLETE(\n    model => 'claude-4-sonnet',\n    prompt => 'Write a friendly and informal customer service reply to: ' || customer_message,\n    model_parameters => { 'temperature': 0.8,'top_p': 0.9}\n  ) AS creative_response,\n  -- Focused response with lower temperature\n  AI_COMPLETE(\n    model => 'claude-4-sonnet',\n    prompt => 'Write a professional customer service reply to: ' || customer_message,\n    model_parameters => { 'temperature': 0.2, 'top_p': 0.1 }\n  ) AS professional_response\nFROM support_tickets;"
  },
  {
   "cell_type": "markdown",
   "id": "d02aaca0-0678-4271-919c-b0ca088c6a2a",
   "metadata": {
    "name": "md_few_shot"
   },
   "source": [
    "## 6. Few‑Shot Prompting with Examples\n",
    "\n",
    "Providing a few examples helps the model learn the structure of the desired output.  Encapsulate examples inside `<examples>` and `<example>` tags to separate them from the main instructions.  Make sure your examples are diverse and representative of real inputs.\n",
    "\n",
    "The next query extracts key fields from support tickets.  It includes two annotated examples of `Input` and `Output` pairs.  The model is instructed to return **only** valid JSON with fields `input`, `issue`, `urgency`, `company`, and `user_id`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e24381-919c-441a-a7e8-eb79b685770c",
   "metadata": {
    "name": "few_shot",
    "language": "sql"
   },
   "outputs": [],
   "source": "WITH ticket_analysis AS (\n  SELECT AI_COMPLETE(\n    'claude-4-sonnet',\n    $$Extract key information from customer support tickets and output ONLY valid JSON with fields \"input\", \"issue\", \"urgency\", \"company\", and \"user_id\".\n\n<examples>\n<example>\nInput: \"The login page won't load on Chrome. Been trying for 20 minutes. UserID: jsmith_99\"\nOutput: {\"input\": \"The login page won't load on Chrome. Been trying for 20 minutes. UserID: jsmith_99\", \"issue\": \"Login failure\", \"urgency\": \"medium\", \"company\": null, \"user_id\": \"jsmith_99\"}\n</example>\n\n<example>\nInput: \"Our API returns a 500 error when calling /invoices. Need a fix ASAP. Company: FinTechCo\"\nOutput: {\"input\": \"Our API returns a 500 error when calling /invoices. Need a fix ASAP. Company: FinTechCo\", \"issue\": \"API error\", \"urgency\": \"high\", \"company\": \"FinTechCo\", \"user_id\": null}\n</example>\n</examples>\n\nExtract key information from this ticket. Return ONLY valid JSON with no other text:\n\"Hey! The dashboard keeps crashing when I try to export my Q3 sales data. This is super urgent because I have a board meeting tomorrow at 9am. My company is TechCorp and my user ID is tc_sarah_m. Please help!!!\"$$\n  ) AS extraction\n)\nSELECT extraction\nFROM ticket_analysis;"
  },
  {
   "cell_type": "markdown",
   "id": "cb7fe780-0d52-42db-a5f1-4cbdb47a8997",
   "metadata": {
    "name": "md_flatten_json",
    "collapsed": false
   },
   "source": "### Flatten the JSON"
  },
  {
   "cell_type": "code",
   "id": "565ef5c5-136c-431a-9d88-861c56cc63b6",
   "metadata": {
    "language": "sql",
    "name": "flatten_json"
   },
   "outputs": [],
   "source": "WITH ticket_analysis AS (\n  SELECT AI_COMPLETE(\n    'claude-4-sonnet',\n    $$Extract key information from customer support tickets and output ONLY valid JSON with fields \"input\", \"issue\", \"urgency\", \"company\", and \"user_id\".\n\nInput: \"The login page won't load on Chrome. Been trying for 20 minutes. UserID: jsmith_99\"\nOutput: {\"input\": \"The login page won't load on Chrome. Been trying for 20 minutes. UserID: jsmith_99\", \"issue\": \"Login failure\", \"urgency\": \"medium\", \"company\": null, \"user_id\": \"jsmith_99\"}\n\nInput: \"Our API returns a 500 error when calling /invoices. Need a fix ASAP. Company: FinTechCo\"\nOutput: {\"input\": \"Our API returns a 500 error when calling /invoices. Need a fix ASAP. Company: FinTechCo\", \"issue\": \"API error\", \"urgency\": \"high\", \"company\": \"FinTechCo\", \"user_id\": null}\n\nExtract key information from this ticket. Return ONLY valid JSON with no other text: \"Hey! The dashboard keeps crashing when I try to export my Q3 sales data. This is super urgent because I have a board meeting tomorrow at 9am. My company is TechCorp and my user ID is tc_sarah_m. Please help!!!\"$$\n  ) AS extraction\n),\nparsed_data AS (\n  SELECT PARSE_JSON(extraction) AS json_data\n  FROM ticket_analysis\n)\nSELECT \n  json_data:input::STRING AS ticket_input,\n  json_data:issue::STRING AS issue_description,\n  json_data:urgency::STRING AS urgency_level,\n  json_data:company::STRING AS company_name,\n  json_data:user_id::STRING AS user_id\nFROM parsed_data;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4e085857-0f18-44e6-9220-b3bc1aef3c1f",
   "metadata": {
    "name": "md_cot_business"
   },
   "source": [
    "## 7. Chain‑of‑Thought Reasoning for Business Decisions\n",
    "\n",
    "Complex decisions benefit from step‑by‑step analysis.  Instruct the model to think through the metrics sequentially inside a `<thinking>` tag and to summarise its recommendation in a separate `<recommendation>` tag.  Listing the steps in the prompt helps the model structure its reasoning and ensures that all relevant factors are considered.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bd395b-95e9-453f-9db7-5e050fee2a89",
   "metadata": {
    "name": "cot_2",
    "language": "sql"
   },
   "outputs": [],
   "source": "-- Step‑by‑step reasoning with enumerated steps and tags\nSELECT AI_COMPLETE(\n  'claude-4-sonnet',\n  $$A SaaS company has these monthly metrics:\n' ||\n  '- Monthly Recurring Revenue (MRR): $125,000\n' ||\n  '- Customer Acquisition Cost (CAC): $450 per customer\n' ||\n  '- Average Revenue Per User (ARPU): $89/month\n' ||\n  '- Monthly Churn Rate: 3.2%\n' ||\n  '- Gross Margin: 78%\n\n' ||\n  'Should they increase their marketing spend by 40% to accelerate growth?\n\n' ||\n  'Think through this step‑by‑step in <thinking> tags:\n' ||\n  '1. Calculate the current customer base and acquisition metrics.\n' ||\n  '2. Determine customer lifetime value (LTV).\n' ||\n  '3. Analyze the LTV/CAC ratio and payback period.\n' ||\n  '4. Consider the impact of a 40% increase in marketing spend.\n' ||\n  '5. Evaluate whether the unit economics support increased spending.\n\n' ||\n  'Then provide your recommendation in <recommendation> tags.\n\n' ||\n  'Format:\n' ||\n  '<thinking>...your detailed analysis and calculations...</thinking>\n' ||\n  '<recommendation>...clear yes/no recommendation with key reasoning...</recommendation>$$\n);\n"
  },
  {
   "cell_type": "markdown",
   "id": "52829746-7748-4c0d-931b-d64a4e22109c",
   "metadata": {
    "name": "md_role_prompting",
    "collapsed": false
   },
   "source": "## 8. Role Prompting with Multiple Messages\n\nAdd roles to `AI_COMPLETE`, such as `system`, `user`, and `assistant`.  Role prompting helps set the persona or tone of the assistant.  Use a `system` message to define behaviour, a `user` message for the query, and optional `assistant` messages to provide context or examples.\n\nIn this example, the `system` message is instructing the model to act as a concise technical assistant.  The `user` message contains the actual question.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174f8aad-1084-4c24-9c74-435c4a7c79c7",
   "metadata": {
    "name": "role_prompting",
    "language": "sql"
   },
   "outputs": [],
   "source": "-- Role prompting using a single string with role instructions\nSELECT AI_COMPLETE(\n  model => 'claude-4-sonnet',\n  prompt => 'You are a helpful technical assistant who provides concise explanations.\n\nUser: Explain the difference between synchronous and asynchronous processing in plain language.',\n  model_parameters => { 'temperature': 0.3 }\n);"
  },
  {
   "cell_type": "markdown",
   "id": "9a7a478b-19b5-4a07-916f-bb0e5468c6c5",
   "metadata": {
    "name": "md_parameters",
    "collapsed": false
   },
   "source": "## 9. Parameter Controls\n\nYou can manage the model configurations within the call to help control for your responses.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072dfd33-6c60-417d-9b35-2c843a3ca881",
   "metadata": {
    "name": "parameters",
    "language": "sql"
   },
   "outputs": [],
   "source": "SELECT AI_COMPLETE(\n  model => 'llama3.2-3b',\n  prompt => 'Write a short 4-line poem about Snowflake. Use exactly 4 lines and end with <END>.\n\nPoem:',\n  model_parameters => {\n    'max_tokens': 80,\n    'temperature': 0.7,\n    'top_p': 0.8,\n    'guardrails': TRUE\n  }\n);"
  },
  {
   "cell_type": "markdown",
   "id": "6ed7f287-9522-433e-bc5e-9cb4b889b08e",
   "metadata": {
    "name": "md_classification_filtering_similarity",
    "collapsed": false
   },
   "source": "## 10. Classification, Filtering and Similarity\n\nSnowflake Cortex includes additional AI SQL functions beyond text generation.  \n`AI_CLASSIFY` assigns labels to text from a list of categories, `AI_FILTER` returns a boolean indicating whether text matches a natural‑language filter, and `AI_SIMILARITY` computes the similarity between two embeddings.  These functions let you build pipelines that classify content, filter records, or rank results before passing them to `AI_COMPLETE`.\n"
  },
  {
   "cell_type": "markdown",
   "id": "4901a6e0-89dc-4db6-8eeb-e6af73e033e5",
   "metadata": {
    "name": "md_classify",
    "collapsed": false
   },
   "source": "### AI_CLASSIFY"
  },
  {
   "cell_type": "code",
   "id": "03c73d88-ad29-400e-92df-1b6fb90e69d2",
   "metadata": {
    "language": "sql",
    "name": "classify_single"
   },
   "outputs": [],
   "source": "-- Enhanced sentiment classification with descriptions\nWITH messages AS (\n  SELECT * FROM VALUES\n    ('Thank you for the great support!'),\n    ('This product is terrible and doesn''t work'),\n    ('The product is okay, nothing special')\n  AS t(message)\n)\nSELECT \n  message,\n  AI_CLASSIFY(\n    message,\n    ARRAY_CONSTRUCT(\n      OBJECT_CONSTRUCT('label', 'Positive', 'description', 'expressing satisfaction, happiness, or approval'),\n      OBJECT_CONSTRUCT('label', 'Negative', 'description', 'expressing dissatisfaction, anger, or disapproval'), \n      OBJECT_CONSTRUCT('label', 'Neutral', 'description', 'neither positive nor negative, factual or indifferent')\n    ),\n    OBJECT_CONSTRUCT(\n      'task_description', 'Classify customer feedback sentiment for support analysis'\n    )\n  ) AS sentiment_result\nFROM messages;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5fccd1f8-5707-429a-bd88-6f8e1507194e",
   "metadata": {
    "language": "sql",
    "name": "classify_multi"
   },
   "outputs": [],
   "source": "-- Multi-label topic classification\nWITH customer_feedback AS (\n  SELECT * FROM VALUES\n    ('The shipping was fast but the product quality is poor'),\n    ('Great customer service and easy returns policy'),\n    ('Expensive pricing but excellent build quality')\n  AS t(feedback)\n)\nSELECT \n  feedback,\n  AI_CLASSIFY(\n    feedback,\n    ARRAY_CONSTRUCT('shipping', 'quality', 'pricing', 'customer_service', 'returns'),\n    OBJECT_CONSTRUCT(\n      'output_mode', 'multi',\n      'task_description', 'Identify all topics mentioned in customer feedback'\n    )\n  ) AS topics\nFROM customer_feedback;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d4ebbf32-b65b-47c9-9ba2-6f00e9ab8d7c",
   "metadata": {
    "name": "md_ai_filter",
    "collapsed": false
   },
   "source": "### AI_FILTER"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ded4da2-aa70-4f67-a5c5-b8e2c784d78e",
   "metadata": {
    "name": "filter",
    "language": "sql",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "-- Filter records using PROMPT function\nWITH products AS (\n  SELECT * FROM VALUES\n    ('A big orange cat painting'),\n    ('Elegant blue evening dress'),\n    ('Fast red sports car')\n  AS t(description)\n)\nSELECT description\nFROM products\nWHERE AI_FILTER(PROMPT('Is this item related to fashion: {0}', description));"
  },
  {
   "cell_type": "markdown",
   "id": "77183975-f60f-4fd9-a6cc-8948e8908edc",
   "metadata": {
    "name": "md_ai_similarity",
    "collapsed": false
   },
   "source": "### AI_SIMILARITY"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9c1c1a-d36c-4809-9538-3c91431ab6b0",
   "metadata": {
    "name": "ai_similarity",
    "language": "sql"
   },
   "outputs": [],
   "source": "-- Compute semantic similarity between sentences\nWITH sentences AS (\n  SELECT * FROM VALUES\n    ('Large language models are transforming business operations.'),\n    ('The weather this weekend will be sunny.'),\n    ('LLMs can write code and analyse text.')\n  AS t(sentence)\n)\nSELECT \n  sentence,\n  AI_SIMILARITY(\n    sentence,\n    'Explain how LLMs impact businesses.'\n  ) AS similarity_score\nFROM sentences\nORDER BY similarity_score DESC;"
  },
  {
   "cell_type": "markdown",
   "id": "a5525e58-dde6-4f84-a0fa-cb6e7ab0d9da",
   "metadata": {
    "name": "md_guardrails_and_data_privacy",
    "collapsed": false
   },
   "source": "## 11. Guardrails and Data Privacy\n\nEnterprise applications must protect sensitive information and guard against inappropriate content.  Generative models can fabricate facts or leak data【180164900185176†L133-L139】.  Implementing guardrails involves:\n\n- **Filtering prompts and outputs:** Use `AI_FILTER` or `AI_CLASSIFY` to detect sensitive content before passing it to an LLM or returning it to users.\n- **Redacting personal data:** Preprocess input to remove or anonymize personally identifiable information (PII).\n- **Human review:** Incorporate humans in the loop to audit critical outputs and handle exceptions【180164900185176†L228-L250】.\n\nThe SQL below illustrates how to screen text for potential sensitive content using `AI_FILTER`.\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd5a1a2-ce67-4009-8766-b6ac50ad3f84",
   "metadata": {
    "name": "ai_filter",
    "language": "sql"
   },
   "outputs": [],
   "source": "-- Detect messages that may contain sensitive information\nWITH messages AS (\n  SELECT * FROM VALUES\n    ('My credit card number is 4111 1111 1111 1111'),\n    ('Looking forward to the meeting tomorrow!')\n  AS t(message)\n)\nSELECT \n  message,\n  AI_FILTER(PROMPT('Does this text contain sensitive personal or financial information: {0}', message)) AS contains_sensitive_data\nFROM messages;"
  }
 ]
}