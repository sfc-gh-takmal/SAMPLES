{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5ae9f1-35b8-4d26-9fa1-e67cb65f670f",
   "metadata": {
    "language": "python",
    "name": "packages_to_include"
   },
   "outputs": [],
   "source": [
    "# Install the following pacakges: pandas and python-pptx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4eda4e-dac6-433f-a7b3-6c57a1b87490",
   "metadata": {
    "language": "python",
    "name": "imports"
   },
   "outputs": [],
   "source": [
    "# ── extract_pptx.py ─────────────────────────────────────────────────────────────\n",
    "\"\"\"\n",
    "Native PPTX extractor for RAG pipelines.\n",
    "• Text → one row per shape (or per nested shape) with (x, y, w, h) in EMUs\n",
    "• Pictures → one row with placeholder text '[IMAGE]' and image metadata\n",
    "• Saves a Parquet file; prints the first few rows so you can eyeball the result\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "from pptx import Presentation\n",
    "from pptx.enum.shapes import MSO_SHAPE_TYPE\n",
    "from collections import deque\n",
    "\n",
    "# We can also use Snowpark for our analyses!\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef26626-1d28-4bc3-a150-33f746ea360f",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "constant_for_microsoft"
   },
   "outputs": [],
   "source": [
    "EMU_PER_INCH = 914_400  # constant from Office spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eabbc98-523c-4c1e-991e-527104fe22d6",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "extract_data_from_pptx"
   },
   "outputs": [],
   "source": [
    "def extract_from_stage(stage_name, file_name, image_stage_name):\n",
    "    \"\"\"Extract content from a PPTX file stored in a Snowflake stage\"\"\"\n",
    "    import os\n",
    "    import tempfile\n",
    "    import shutil\n",
    "    from pptx import Presentation\n",
    "    from collections import deque\n",
    "    \n",
    "    # Create a temporary directory\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    temp_path = os.path.join(temp_dir, file_name)\n",
    "    \n",
    "    try:\n",
    "        # Download file from stage to temp directory\n",
    "        session.file.get(f\"@{stage_name}/{file_name}\", temp_dir)\n",
    "        \n",
    "        # The actual file path might be different - find the downloaded file\n",
    "        actual_file_path = os.path.join(temp_dir, file_name)\n",
    "        \n",
    "        # Check if the downloaded item is a directory\n",
    "        if os.path.isdir(actual_file_path):\n",
    "            # Look for the file inside the directory\n",
    "            files = os.listdir(actual_file_path)\n",
    "            if files:\n",
    "                # Use the first file found\n",
    "                actual_file_path = os.path.join(actual_file_path, files[0])\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"No files found in {actual_file_path}\")\n",
    "        \n",
    "        # Process the file\n",
    "        prs = Presentation(actual_file_path)\n",
    "        rows = []\n",
    "        \n",
    "        for idx, slide in enumerate(prs.slides, start=1):\n",
    "            for shape_data in process_slide_shapes(slide, idx, image_stage_name):\n",
    "                rows.append(shape_data)\n",
    "\n",
    "        if not rows:\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "        df = pd.DataFrame(rows)\n",
    "        \n",
    "        # Extract coordinates from bbox for sorting\n",
    "        df[\"top\"] = df[\"bbox\"].apply(lambda x: x[1])\n",
    "        df[\"left\"] = df[\"bbox\"].apply(lambda x: x[0])\n",
    "        \n",
    "        # Group elements into columns based on horizontal position \n",
    "        df[\"column_group\"] = pd.cut(df[\"left\"], bins=10, labels=False)\n",
    "        \n",
    "        # Sort by slide, then column group, then vertical position\n",
    "        df = df.sort_values(by=[\"slide\", \"column_group\", \"top\"])\n",
    "        \n",
    "        # Drop the temporary columns\n",
    "        df = df.drop(columns=[\"top\", \"left\", \"column_group\"])\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    finally:\n",
    "        # Clean up temp directory and all contents\n",
    "        shutil.rmtree(temp_dir, ignore_errors=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9f20ae-4a3f-4ae1-90f9-b77aea821a93",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "walk_through_slides"
   },
   "outputs": [],
   "source": [
    "def process_slide_shapes(slide, slide_idx, image_stage_name):\n",
    "    \"\"\"Process shapes from a slide and return data for each shape\"\"\"\n",
    "    from collections import deque\n",
    "    from pptx.enum.shapes import MSO_SHAPE_TYPE\n",
    "    import tempfile\n",
    "    import os\n",
    "    \n",
    "    stack = deque(slide.shapes)\n",
    "    results = []\n",
    "    \n",
    "    while stack:\n",
    "        shp = stack.pop()\n",
    "        # Recursively expand group shapes\n",
    "        if shp.shape_type == MSO_SHAPE_TYPE.GROUP:\n",
    "            stack.extend(shp.shapes)\n",
    "            continue\n",
    "\n",
    "        bbox = [int(shp.left), int(shp.top), int(shp.width), int(shp.height)]\n",
    "\n",
    "        if shp.has_text_frame and shp.text_frame.text.strip():\n",
    "            results.append({\n",
    "                \"slide\": slide_idx,\n",
    "                \"shape_id\": shp.shape_id,\n",
    "                \"type\": \"TEXT\",\n",
    "                \"content\": shp.text_frame.text.strip(),\n",
    "                \"bbox\": bbox,\n",
    "            })\n",
    "\n",
    "        elif shp.shape_type == MSO_SHAPE_TYPE.PICTURE:\n",
    "            image = shp.image\n",
    "            name = f\"slide{slide_idx}_img{shp.shape_id}{image.ext}\"\n",
    "            \n",
    "            # Create temp file for the image\n",
    "            temp_img_path = os.path.join(tempfile.mkdtemp(), name)\n",
    "            \n",
    "            try:\n",
    "                # Save image to temp file\n",
    "                with open(temp_img_path, 'wb') as f:\n",
    "                    f.write(image.blob)\n",
    "                \n",
    "                # Upload to Snowflake stage\n",
    "                session.file.put(temp_img_path, f\"@{image_stage_name}/\", auto_compress=False, overwrite=True)\n",
    "                \n",
    "                results.append({\n",
    "                    \"slide\": slide_idx,\n",
    "                    \"shape_id\": shp.shape_id,\n",
    "                    \"type\": \"IMAGE\",\n",
    "                    \"content\": \"[IMAGE]\",\n",
    "                    \"file\": name,\n",
    "                    \"bbox\": bbox,\n",
    "                })\n",
    "            finally:\n",
    "                # Clean up\n",
    "                if os.path.exists(temp_img_path):\n",
    "                    os.remove(temp_img_path)\n",
    "                if os.path.exists(os.path.dirname(temp_img_path)):\n",
    "                    os.rmdir(os.path.dirname(temp_img_path))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4091401-9147-474e-9c3e-9d433f5a140e",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "create_df"
   },
   "outputs": [],
   "source": [
    "def save_to_snowflake_table(df, table_name):\n",
    "    \"\"\"Save the extracted data to a Snowflake table\"\"\"\n",
    "    # Reset to standard RangeIndex so no warning appears\n",
    "    df_copy = df.reset_index(drop=True).copy()\n",
    "    df_copy[\"bbox\"] = df_copy[\"bbox\"].apply(str)\n",
    "\n",
    "    snowpark_df = session.create_dataframe(df_copy)\n",
    "    snowpark_df.write.mode(\"overwrite\").save_as_table(table_name)\n",
    "    return f\"Saved {len(df_copy)} records to table {table_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979f73f2-7790-45bf-9e88-53d387b5aebe",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "create_stages_if_needed"
   },
   "outputs": [],
   "source": [
    "# Setup stages if they don't exist\n",
    "\n",
    "# session.sql(\"\"\"\n",
    "# CREATE STAGE IF NOT EXISTS PPTX\n",
    "#   ENCRYPTION = (TYPE = 'SNOWFLAKE_SSE')          -- server-side encryption by Snowflake KMS\n",
    "#   DIRECTORY  = (ENABLE = TRUE)                   -- keeps a manifest of everything you PUT\n",
    "#   );\n",
    "# \"\"\").collect()\n",
    "\n",
    "# session.sql(\"\"\"\n",
    "# CREATE STAGE IF NOT EXISTS PPTX_IMAGES\n",
    "#   ENCRYPTION = (TYPE = 'SNOWFLAKE_SSE')          -- same SSE envelope encryption\n",
    "#   DIRECTORY  = (ENABLE = TRUE)\n",
    "#   );\n",
    "# \"\"\").collect()\n",
    "\n",
    "# Upload a PPTX file to the stage (can be done through Snowflake UI or code)\n",
    "# session.file.put(\"local_file.pptx\", \"@pptx_files/\", overwrite=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29934d8c-9c29-4e98-9ca9-adf1d3cdc0eb",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "display_df_from_pptx"
   },
   "outputs": [],
   "source": [
    "# Extract content\n",
    "df = extract_from_stage(\"PPTX\", \"sample3.pptx\", \"PPTX_IMAGES\")\n",
    "\n",
    "# Display the data\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9b794c-4ce5-416b-b624-146771fbe1ca",
   "metadata": {
    "collapsed": false,
    "name": "saving_to_sf_table"
   },
   "source": [
    "# Saving to Snowflake Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4b21e6-661c-4777-a3e7-148bf013fe77",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "save_to_table"
   },
   "outputs": [],
   "source": [
    "# # Save to Snowflake table\n",
    "result = save_to_snowflake_table(df, \"PPTX_EXTRACTED_CONTENT\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d96523-7c7d-4009-8a0c-39f13dca7b60",
   "metadata": {
    "language": "sql",
    "name": "view_table"
   },
   "outputs": [],
   "source": [
    "select *\n",
    "from pptx_extracted_content;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914644e9-1e1e-4165-8eb5-0a182d4426fb",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "drop_snowflake_table"
   },
   "outputs": [],
   "source": [
    "-- drop table pptx_extracted_content;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "taj.akmal@snowflake.com",
   "authorId": "1935988576203",
   "authorName": "TAJA",
   "lastEditTime": 1747399292310,
   "notebookId": "ewk6vgdsghwscdcgv22x",
   "sessionId": "91a3f8b2-9c04-40ef-b883-fe2762610352"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
